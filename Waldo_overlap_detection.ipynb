{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ae2ff-4da0-4a28-95f4-be0206bb87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, cv2, numpy as np, matplotlib.pyplot as plt, matplotlib.image as mpimg, pandas as pd, math, statistics, scipy\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from PIL import Image\n",
    "from scipy import ndimage, stats\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# base directory should contain 1 or more matched \"pairs\" of images suitable for calibration\n",
    "# ideal imagery for calibration includes near-sea level land at the interior margin\n",
    "\n",
    "base_dir = r\"D:\\Waldo_overlap_examples\\20220812_R-uncropped\"\n",
    "# the file extension of the imagery. We could code a different way to read in images, but this works.\n",
    "img_ext = \"jpg\"\n",
    "\n",
    "img_list = glob.glob(f\"{base_dir}//*.jpg\", recursive=True)\n",
    "\n",
    "# identify all file pairs with the same name aside from the first character\n",
    "pair_list = np.unique([i.split(\"\\\\\")[-1][1:] for i in img_list], return_counts=True)\n",
    "pair_list = pair_list[0][pair_list[1]==2]\n",
    "# this variable sets left vs. right prefixes for the image files\n",
    "prefixes = {'right':0, 'left':1}\n",
    "pairs = [{k: f\"{base_dir}\\\\{v}{i}\" for k, v in prefixes.items()} for i in pair_list]\n",
    "\n",
    "# change the index number (\"0\") to change the pair\n",
    "trgt_pair = pairs[2]\n",
    "print(trgt_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfd2f6-0be1-49f7-8dbc-1c3fce7d69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section reads in the images and displays them\n",
    "img_l = mpimg.imread(trgt_pair[\"left\"])\n",
    "img_r = ndimage.rotate(mpimg.imread(trgt_pair[\"right\"]), 180)\n",
    "\n",
    "im_height, im_width, im_channels = img_l.shape\n",
    "\n",
    "def display_image_pair(left_image, right_image):\n",
    "    rcParams['figure.figsize'] = 11 ,8\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    ax[0].imshow(left_image)\n",
    "    ax[1].imshow(right_image)\n",
    "    ax[0].set_title(\"Left Image\")\n",
    "    ax[1].set_title(\"Right Image\")\n",
    "\n",
    "display_image_pair(img_l, img_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8575d-70ee-43f9-9ca8-dfdc1839afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section crops the images to just the inner margin where we expect overlap\n",
    "# to reduce the number of spurious tie points possible\n",
    "inner_margin = 700\n",
    "img1 = img_l[0:im_height, im_width-inner_margin:im_width]\n",
    "img2 = img_r[0:im_height, 0:inner_margin]\n",
    "display_image_pair(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad7a30-89ce-444e-b416-16f83ea7cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize ORB detector\n",
    "#orb = cv2.ORB_create(1000000)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT_create(1000000)\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# Use BFMatcher to find matches\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "matches = bf.match(des1, des2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941eaef-881a-4c7d-9ab5-3e2764b948bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section processes the matched tiepoints for handling\n",
    "\n",
    "# Sort matches by distance\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "des1 = des1.astype(np.float32)\n",
    "des2 = des2.astype(np.float32)\n",
    "\n",
    "def trigbearing(p1, p2):\n",
    "    return (math.degrees(math.atan2(p2[1]-p1[1], p2[0]-p1[0])) + 360) % 360\n",
    "\n",
    "def slope(p1, p2):\n",
    "    if p2[0] == p1[0]:\n",
    "        return 0\n",
    "    else: return (p2[1]-p1[1])/(p2[0]-p1[0])\n",
    "        \n",
    "# Create dataframe with distance and slope between points\n",
    "df = pd.DataFrame([[mat, kp1[mat.queryIdx], kp1[mat.queryIdx].pt, kp2[mat.trainIdx], kp2[mat.trainIdx].pt] for mat in matches], columns=['matches', 'kp1', 'kp1_pt','kp2', 'kp2_pt'])\n",
    "df['kp1_pt_orig_x'] = [i[0]+im_width-(inner_margin+1) for i in df['kp1_pt']]\n",
    "df['kp2_pt_orig_x'] = [i[0] for i in df['kp2_pt']]\n",
    "df['kp1_pt_orig_y'] = [i[0] for i in df['kp1_pt']]\n",
    "df['kp2_pt_orig_y'] = [i[0] for i in df['kp2_pt']]\n",
    "df['distance'] = [math.dist(i.kp1_pt, i.kp2_pt) for i in df.itertuples()]\n",
    "df[\"sin_bearing\"] = [math.sin(trigbearing(i.kp1_pt, i.kp2_pt)) for i in df.itertuples()]\n",
    "df[\"cos_bearing\"] = [math.cos(trigbearing(i.kp1_pt, i.kp2_pt)) for i in df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443c6aa-3785-4922-a532-3215bb8078f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section proposes high-quality matches\n",
    "# using an outlier removal algorithm called IsolationForest\n",
    "# https://www.digitalocean.com/community/tutorials/anomaly-detection-isolation-forest\n",
    "\n",
    "clf = IsolationForest(contamination=float(0.5)).fit(df[['distance', 'sin_bearing', 'cos_bearing']])\n",
    "df['scores']=clf.decision_function(df[['distance', 'sin_bearing', 'cos_bearing']])\n",
    "df_cluster = df.loc[df['scores']>=0,].copy()\n",
    "df_anomaly = df.loc[df['scores']< 0,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a13868-730a-433f-9f50-a88c65b0dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this code is for generating nearest high-quality neighbors around each point\n",
    "### so we can look at the \"constellation\" of matched keypoints around them\n",
    "### and see how much the constellation of keypoints at one end\n",
    "### differs from the constellation on the other end, based on nearest-neighbor distances\n",
    "\n",
    "# This function reads in 2 datasets of matches: a full dataset, and a subset of high quality matches\n",
    "def median_nn_differences_two_datasets(df, df_cluster):\n",
    "\n",
    "    # create an array of keypoint1 locations from all matches\n",
    "    x = [np.array(i) for i in df['kp1_pt']]\n",
    "    # create an array of keypoint1 locations from only high-quality matches\n",
    "    y = [np.array(i) for i in df_cluster['kp1_pt']]\n",
    "    # generate nearest neighbors tree for HQ points\n",
    "    tree =scipy.spatial.KDTree(y)    \n",
    "    # find nearest HQ neighbors for all points\n",
    "    ordered_neighbors = tree.query(x, min(11, len(y)))\n",
    "    \n",
    "    # pull in an array of keypoint2 locations from all matches\n",
    "    x_kp2s = [np.array(i) for i in df['kp2_pt']]\n",
    "    # pull in an array of the original \"index\" values, used to call HQ matches\n",
    "    y_idxs = np.array(df_cluster.reset_index()['index'])\n",
    "    # replace the \"nearest neighbor\" table with original index values for complete dataframe\n",
    "    orig_indices = np.array([[int(y_idxs[j]) for j in i] for i in ordered_neighbors[1]])\n",
    "    # NN algorithms will include the \"self\" point if it's present as a closest neighbor\n",
    "    # this line of code removes the \"self\" point, if present\n",
    "    orig_indices = [np.delete(i, np.where(i == n))[0:min(10, len(y)-1)] for n, i in enumerate(orig_indices)]\n",
    "    # convert the index lists to KP1 and KP2 point locations\n",
    "    kp1_array = [[df.loc[j, 'kp1_pt'] for j in i] for i in orig_indices]\n",
    "    kp2_array = [[df.loc[j, 'kp2_pt'] for j in i] for i in orig_indices]\n",
    "    # calculate distances between reference points and their neighbors\n",
    "    kp1_nn_distances = [[math.dist(x[n], j) for j in i] for n, i in enumerate(kp1_array)]\n",
    "    kp2_nn_distances = [[math.dist(x_kp2s[n], j) for j in i] for n, i in enumerate(kp2_array)]\n",
    "    # get the difference of these distances as aggregate metric of \"constellation similarity\"\n",
    "    # then take median, to see if a point is overall consistent in its constellation or not\n",
    "    median_kp1_kp2_distance_diff = np.median(np.array(kp1_nn_distances) - np.array(kp2_nn_distances), axis=1)\n",
    "    return median_kp1_kp2_distance_diff\n",
    "\n",
    "df['constellation_similarity'] = median_nn_differences_two_datasets(df, df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de54589-2ada-4758-a20b-2c5b677a6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering primarily based on constellation similarity\n",
    "constellation_threshold = 10\n",
    "\n",
    "# leaving this code in, in case we ever want to try distance thresholding\n",
    "# distance_percentile = 1\n",
    "# distance_percentile = (0.5*(1-distance_percentile), (distance_percentile-(0.5*(1-distance_percentile))))\n",
    "\n",
    "df_cluster =  df[abs(df['constellation_similarity']) < constellation_threshold \\\n",
    "\n",
    "                #& df[(df['distance'].between(df['distance'].quantile(distance_percentile[0]), df['distance'].quantile(distance_percentile[1]))) \\\n",
    "                ].copy()\n",
    "\n",
    "# one more round of light filtering after selecting for constellation similarity\n",
    "clf = IsolationForest(contamination=float(0.005)).fit(df_cluster[['distance', 'sin_bearing', 'cos_bearing', 'constellation_similarity']])\n",
    "df_cluster['scores']=clf.decision_function(df_cluster[['distance', 'sin_bearing', 'cos_bearing', 'constellation_similarity']])\n",
    "df_cluster = df_cluster.loc[df['scores']>=0,].copy()\n",
    "df_anomaly = df_cluster.loc[df['scores']< 0,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5000f7-817f-4f36-9df5-6759fc712b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section displays the matches on the cropped imagery.\n",
    "# Press Q key to close the window and proceed when finished.\n",
    "\n",
    "display_matches = True\n",
    "if display_matches == True:\n",
    "    img_matches = cv2.drawMatches(\n",
    "        img1, kp1, img2, kp2, list(df_cluster.matches), None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.namedWindow('matches', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"matches\", img_matches)\n",
    "    wait_time = 1000\n",
    "    while cv2.getWindowProperty('matches', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "        keyCode = cv2.waitKey(wait_time)\n",
    "        if (keyCode & 0xFF) == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74c5eb-19d3-4eb0-bb23-cbd6d30d5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cluster\n",
    "\n",
    "# This section looks at the horizontal displacement of features\n",
    "# and calculates their distance to the edge of the image to determine\n",
    "# the total size of the overlap zone\n",
    "\n",
    "df['kp1_pt_orig_x'] = [i[0]+im_width-(inner_margin+1) for i in df['kp1_pt']]\n",
    "df['kp2_pt_orig_x'] = [i[0] for i in df['kp2_pt']]\n",
    "df['kp1_pt_orig_y'] = [i[0] for i in df['kp1_pt']]\n",
    "df['kp2_pt_orig_y'] = [i[0] for i in df['kp2_pt']]\n",
    "vertical_displacement = df['kp2_pt_orig_y']-df['kp1_pt_orig_y']\n",
    "df = df.sort_values('kp1_pt_orig_x', ascending=False)\n",
    "edge_of_im1_on_im2 = margin_r = statistics.median([i.kp2_pt_orig_x + (im_width-i.kp1_pt_orig_x) for i in df.itertuples()])\n",
    "df = df.sort_values('kp2_pt_orig_x', ascending=True)\n",
    "edge_of_im2_on_im1 = statistics.median([i.kp1_pt_orig_x - i.kp2_pt_orig_x for i in df.itertuples()])\n",
    "margin_l = im_width - edge_of_im2_on_im1\n",
    "mean_margin = statistics.mean([margin_l, margin_r])\n",
    "\n",
    "# this bit just digests and presents key metrics of overlap\n",
    "\n",
    "print(f\"Average vertical displacement of {round(statistics.mean(vertical_displacement), 2)} pixels from left image to right\")\n",
    "print(f\"Average of {round(mean_margin, 2)} pixels of horizontal overlap\")\n",
    "dead_center = mean_margin/2\n",
    "print(f\"Crop at least {math.ceil(dead_center)} pixels to eliminate overlap\")\n",
    "percent_overlap = mean_margin/im_width\n",
    "print(f\"{round(percent_overlap, 4)}% of each image overlaps its partner\")\n",
    "waldo_aovw = 39.597752709049864\n",
    "angle_of_overlap = percent_overlap * waldo_aovw\n",
    "print(f\"Fields of view extend {round(angle_of_overlap, 2)}° past nadir\")\n",
    "waldo_angle = waldo_aovw - angle_of_overlap\n",
    "print(f\"Waldos were mounted {round(waldo_angle, 2)}° apart\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
